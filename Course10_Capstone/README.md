# Introduction

This is the tenth course of the Coursera Data Science Specialization, **Data Science Capstone**. This course focuses on analyzing a large corpus of text documents to discover the structure in the data and how words are put together to build a predictive text model.

# Contents
## Task 1: Getting and cleaning the data
 - Tokenization: identifying appropriate tokens such as words, punctuation, and numbers. Writing a function that takes a file as input and returns a tokenized version of it.
    - [tokenization.R](https://github.com/wamber-aww/coursera-data-science/blob/gh-pages/Course10_Capstone/tokenization.R)
 - Profanity filtering - removing profanity and other words you do not want to predict.
    - [rmProfanity.R](https://github.com/wamber-aww/coursera-data-science/blob/gh-pages/Course10_Capstone/rmProfanity.R)
 - [Task 1 writeup](https://wamber-aww.github.io/coursera-data-science/Course10_Capstone/Task1.html)
 - [Week 1 quiz](https://wamber-aww.github.io/coursera-data-science/Course10_Capstone/W1Quiz.html)
